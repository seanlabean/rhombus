# PythonOpenMPI

A generalizable python-mpi utility for task-based parallel programming.

This implementation of task-based parallel programming consists of one root processor, and any number of worker processors. The root breaks a portion of a job into bite sized chunks (like a single file) which are then sent to the workers. While the workers... well... work, the root sits and waits. When a working finishes with its allotted chunk, it pings the root node and asks for another chunk, which the root node then provides. Therefore no worker is ever left without something to do.

This is fundamentally different and more efficient than data-bases paralllel processing in which an **entire** job is split into n equally sized chunks (where n is the number of processors) and sent to the worker processors. In this method, when a worker is done processing, it does not need to ask the root node for any more work (since everything has already been distributed to the workers). Therefore, although the task is being completed in parallel, there is a chance that workers will be left idle while they wait for other workers to finish.

## Necessary packages
In addition to whichever packages you use for your process you wish to parallelize, you will need to ensure you have working installs of the following:

* python v3.X
* [OpenMPI v4.X.X](https://www.open-mpi.org/software/ompi/v4.0/)
* mpi4py python library

Ensure you have a properly configured and installed version of OpenMPI with your PATH and PYTHONPATH correctly pointed to the install directory before attempting to `pip install mpi4py`.

## Running the test problem
To run the test problem:
1. `cd` into the `/simple_example` directory.
2. do `python gen_empty_files.py` this will create a sub-directory /files within /simple_example and will populate the directory with 10 blank text files of the form file_X.txt where X runs from 0 to 9. The number of test files created can be changed by editing gen_empty_files.py
3. do `mpiexec -n {num_procs} python test_script.py` while replacing num_procs with the number of processors you wish to parallelize the task across.

The output will reveal the communication between the supervisor processor and the worker processors: transerfing "to-do" data around, sending completed messages back, etc.

This particular command line call will only parallelize across a single node of any number of processors. If multiple nodes are needed, you will need to provide mpiexec with a hostfile.

## How to parallelize your specific task
Upon investigating the perform_task_in_parallel() funciton within `mpi_utilities.py` you will notice that the "task" can be any function, with any number of input args and kwargs. If your task can be condensed into a single function with a discrete amount of input work, it can be parallelized with this routine. To utilize, call ```perform_task_in_parallel(your_func, [args], {kwargs}, input_data, chunk_size, rank, size, comm, root, debug=False)```
where rank, size, and comm are generated by the initialize_mpi() call. chunk_size is the amount of input work to be sent to each processor when it asks for something to do. [args] and {kwargs} are the arugments and keyword arguments for your_func.

This repository is meant to aid other graduate students in the Drexel University Physics Department, the University at large, and beyond.

Contributors:

- Sean C. Lewis (owner, scl63@drexel.edu)

- Evan Arena